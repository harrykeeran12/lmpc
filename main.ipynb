{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this project, `ollama` must be installed. This is a package that allows for LLM usage, easily. \n",
    "\n",
    "The `ollama` server can be run using `ollama serve`, for testing purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (0.2.0)\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.35.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from ollama) (0.27.0)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting numpy<2,>=1.19.3 (from streamlit)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging<25,>=16.8 in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from streamlit) (24.0)\n",
      "Collecting pandas<3,>=1.3.0 (from streamlit)\n",
      "  Downloading pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting pillow<11,>=7.1.0 (from streamlit)\n",
      "  Downloading pillow-10.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting protobuf<5,>=3.20 (from streamlit)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-16.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting requests<3,>=2.27 (from streamlit)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from streamlit) (4.11.0)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from streamlit) (6.4)\n",
      "Collecting jinja2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting toolz (from altair<6,>=4.0->streamlit)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.3.0->streamlit)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.3.0->streamlit)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.27->streamlit)\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27->streamlit)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair<6,>=4.0->streamlit)\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.18.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp312-cp312-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.1.0-cp312-cp312-macosx_11_0_arm64.whl (26.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl (119 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl (18 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.18.1-cp312-cp312-macosx_11_0_arm64.whl (323 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pytz, urllib3, tzdata, toolz, toml, tenacity, smmap, rpds-py, protobuf, pillow, numpy, mdurl, MarkupSafe, click, charset-normalizer, cachetools, blinker, attrs, requests, referencing, pyarrow, pandas, markdown-it-py, jinja2, gitdb, rich, pydeck, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed MarkupSafe-2.1.5 altair-5.3.0 attrs-23.2.0 blinker-1.8.2 cachetools-5.3.3 charset-normalizer-3.3.2 click-8.1.7 gitdb-4.0.11 gitpython-3.1.43 jinja2-3.1.4 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 markdown-it-py-3.0.0 mdurl-0.1.2 numpy-1.26.4 pandas-2.2.2 pillow-10.3.0 protobuf-4.25.3 pyarrow-16.1.0 pydeck-0.9.1 pytz-2024.1 referencing-0.35.1 requests-2.32.3 rich-13.7.1 rpds-py-0.18.1 smmap-5.0.1 streamlit-1.35.0 tenacity-8.3.0 toml-0.10.2 toolz-0.12.1 tzdata-2024.1 urllib3-2.2.1\n"
     ]
    }
   ],
   "source": [
    "! pip3 install ollama streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed models on local ollama instance:\n",
      "phi3:mini\n"
     ]
    }
   ],
   "source": [
    "from httpx import ConnectError\n",
    "import ollama\n",
    "import typing\n",
    "import subprocess\n",
    "import streamlit as st\n",
    "# Check if models are installed or not.\n",
    "try:\n",
    "    print(\"Installed models on local ollama instance:\")\n",
    "    # print(ollama.list())\n",
    "    INSTALLEDMODELS: list[str] = []\n",
    "    for modelName in ollama.list()[\"models\"]:\n",
    "        print(modelName[\"name\"])\n",
    "        INSTALLEDMODELS.append(modelName[\"name\"])\n",
    "except ConnectError:\n",
    "    raise Exception(\"ollama server is not online. \\nUse ollama serve to run the ollama daemon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papers generated use any notes included in the `NOTEFILE`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A mock paper can be generated by__\n",
    "- supplying notes(required), \n",
    "- supplying an LLM model name(default will be `phi3:mini` ), \n",
    "- providing the number of questions(between 2 and 5), \n",
    "- the total number of marks that the questions should total up to(default will be 100), \n",
    "- the question type(short-form questions, multiple choice questions(default), essay based questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' If true, then questions can be divided into a,b,c or i, ii, iii.\\n    Question subdivision support can be added later. \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Check defaults and make sure there are no exceptions. \"\"\"\n",
    "\n",
    "MODELNAME: str = \"phi3:mini\"\n",
    "\n",
    "if MODELNAME not in INSTALLEDMODELS:\n",
    "    raise Exception(f\"Model name {MODELNAME} not in installed models.\")\n",
    "else:\n",
    "    ollama.pull(MODELNAME)\n",
    "\n",
    "NOTEFILE: str = \"notes.txt\"\n",
    "\n",
    "try:\n",
    "    with open(NOTEFILE, \"r\") as questionTemplate:\n",
    "        NOTES: str = \"\".join(questionTemplate.readlines())\n",
    "except FileNotFoundError:\n",
    "    raise Exception(f\"Could not find {NOTEFILE}.\")\n",
    "\n",
    "\n",
    "QUESTIONNUMBER: int = 5\n",
    "\n",
    "if QUESTIONNUMBER > 5 or QUESTIONNUMBER < 2:\n",
    "    raise Exception(\"Question amount not suitable.\")\n",
    "\n",
    "TOTALMARKS: int = 10\n",
    "\n",
    "if TOTALMARKS // QUESTIONNUMBER < 1:\n",
    "    raise Exception(\"Number of marks is too low.\")\n",
    "\n",
    "QUESTIONTYPE: str = \"long\"\n",
    "\"\"\" This can differ between short, long and mcq.\"\"\"\n",
    "\n",
    "# try:\n",
    "#     with open(\"exampleQuestions.txt\", \"r\") as QUESTIONSFILE:\n",
    "#         EXAMPLEQUESTIONS = \"\".join(QUESTIONSFILE.readlines())\n",
    "# except OSError:\n",
    "#     raise Exception(\"Question file does not exist.\")\n",
    "\n",
    "\"\"\" If true, then questions can be divided into a,b,c or i, ii, iii.\n",
    "    Question subdivision support can be added later. \n",
    "\"\"\"\n",
    "# if QUESTIONNUMBER > 10:\n",
    "#     SUBDIVISIONS = True\n",
    "# else:\n",
    "#     SUBDIVISIONS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionType:\n",
    "    \"\"\"This class houses the different types of questions, and the prompts, that can be created by the program for each paper.\n",
    "    Parameters:\n",
    "    name: str - the name of the question type.\n",
    "    systemPrompt: str - the initial prompt that should be added to generate the questions.\n",
    "    examplePrompt: str - any example questions that would aid in generation. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, systemPrompt: str, examplePrompt: str = None) -> None:\n",
    "        self.name = name\n",
    "        self.systemPrompt = systemPrompt\n",
    "        self.examplePrompt = examplePrompt\n",
    "\n",
    "\n",
    "short = QuestionType(\n",
    "    \"short\", \"You must generate short questions that are clear to understand.\")\n",
    "long = QuestionType(\n",
    "    \"long\", \"You must generate long answer questions. Examples include essay questions.\")\n",
    "mcq = QuestionType(\n",
    "    \"mcq\", \"You must generate short multiple choice questions that can be answered using one sentence. Do not return the answers or options.\", )\n",
    "ALLQUESTIONTYPES: dict[str, QuestionType] = {}\n",
    "\n",
    "ALLQUESTIONTYPES[short.name] = short\n",
    "ALLQUESTIONTYPES[long.name] = long\n",
    "ALLQUESTIONTYPES[mcq.name] = mcq\n",
    "\n",
    "\n",
    "if QUESTIONTYPE not in ALLQUESTIONTYPES.keys():\n",
    "    raise Exception(\"Invalid question type.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruct: Rewrite, reorganise and summmarise these notes below into one simple clear paragraph. Make sentences simple. Do not add any other information. Do not write the questions. Write each note in a definition-example-explanation structure. Make sure that the data is all in plain-text. \n",
      " \n",
      " A distributed system is a collection of autonomous computers linked by a network, with software to produce an integrated computing infrastructure. \n",
      "It is a set of discrete computers that perform a computation together, as if they were a single computing system, as a network of processes, which interact with one another to achieve a goal. These systems are required for processes like resource sharing, computation speed up via parallelism, and fault tolerance and uncertainty management. \n",
      "Information is processed data; data that is organised, meaningful + useful. Security is when you prevent unauthorised access to information + services, and how to maintain availability of information + services to authorised users. Distributed systems rely on interprocess communications, which involve networking layers. \n",
      "The TCP protocol implements a reliable end-to-end communication. Middleware helps application authors write software that is intended to run on more than one machine at a time. An example would be the Java RMI. \n",
      "A model is a simple abstraction that preserves the essential features but hides the implementation details.\n",
      "A **remote procedure call** are programming means that hide aspects of identifying and finding remote procedures using an IP address. \n",
      "\n",
      "**Data marshalling** is a conversion of data to a platform independent format. \n",
      "\n",
      "A **remote method invocation** hides the data marshalling, and uses an object based paradigm.\n",
      "In a RMI application, the server creates a **set of remote objects**, and makes the **references to the objects accessible**. It waits for client requests to invoke methods on these objects. The client obtains the remote references and invokes the method on the remote objects.\n",
      "\n",
      "The `rmiregistry` is used to locate remote objects. To let RMI behave identically to LMI(local method invocation), the RMI infrastructure manages communication via the use of proxies. \n",
      "\n",
      "Dynamic program code loading is when Java objects are instantiated from compiled Java classes, which are loaded into the local JVM.\n",
      "A **stub** is a proxy for a remote object, and acts as a local interpretation of the object, as a **remote reference**. It is a type of RMI middleware.\n",
      "\n",
      "The **skeleton** or dispatcher takes messages from the stub and invokes the methods onto the remote object.\n",
      "An RMI registry runs on a computer that hosts remote objects. It is the central binder for remote objects, and contains a table mapping of URLs → remote object references. It is accessed by methods like `rebind(), bind(), unbind() and lookup()`. \n",
      "\n",
      "If the server is behind a firewall and specific ports are open, we specify what ports are used by using `java.rmi.UnicastRemoteObject.exportObject(java.rmi.Remote obj, int port)`. \n",
      "\n",
      "To maintain the security of an application, we use a **security policy**, which allows the Java code to perform certain actions, using `System.setProperty(\"java.security.policy\", \"name.policy\")`. We can create a `name.policy` file by using the `policytool` in the JVM. \n",
      "\n",
      "We can obtain the class specifications for remote objects via the **local file system** or **using HTTP from a web server.** \n",
      " \n",
      " \n",
      "Output: \n",
      " A distributed system is an assembly of autonomous computers connected through a network, operating as one cohesive unit to accomplish tasks like resource sharing and increasing computation speed through parallelism, while managing fault tolerance and uncertainty. These systems utilize interprocess communications, involving networking layers such as the TCP protocol for reliable communication. Middleware tools, exemplified by Java RMI (Remote Method Invocation), facilitate remote procedure calls that abstract essential features without exposing implementation details. In an RMI setup, objects are remotely referenced through a registry, with stubs acting as local proxies to invoke methods on these objects using the skeleton or dispatcher. Data marshalling transforms platform-specific data into a universal format for remote method invocations. For security purposes, Java'e `java.security.policy` manages permissions and can be customized through policies stored in files. Distributed systems also have their object specifications accessed either from the local file system or over HTTP via a web server.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Modify the notes such that they are in a structure that is best for the question type.\"\"\"\n",
    "NOTESREWRITE = f\"Instruct: Rewrite, reorganise and summmarise these notes below into one simple clear paragraph. Make sentences simple. Do not add any other information. Do not write the questions. Write each note in a definition-example-explanation structure. Make sure that the data is all in plain-text. \\n \\n {NOTES} \\n \\n \\nOutput: \" \n",
    "\n",
    "print(NOTESREWRITE)\n",
    "\n",
    "rewriteNotes = ollama.generate(model=MODELNAME, prompt=NOTESREWRITE)\n",
    "\n",
    "print(rewriteNotes[\"response\"])\n",
    "\n",
    "NOTES = rewriteNotes[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruct: Generate 5 questions, in a list. Each question should be written as a string, and should be separated by one new line character \\n each. Questions should not be numbered. \n",
      "For example, for 4 questions about famous authors would be generated as\n",
      " \"Which author beginning with the letter M contributed the most to American literary fiction?\"\\n\"When was this author born?\"\\n\"Which famous comet was associated with this author?\"\\n\"Did this author have a pen-name?\"\n",
      " You must generate long answer questions. Examples include essay questions.\n",
      "Please generate the questions from these notes: \n",
      "  A distributed system is an assembly of autonomous computers connected through a network, operating as one cohesive unit to accomplish tasks like resource sharing and increasing computation speed through parallelism, while managing fault tolerance and uncertainty. These systems utilize interprocess communications, involving networking layers such as the TCP protocol for reliable communication. Middleware tools, exemplified by Java RMI (Remote Method Invocation), facilitate remote procedure calls that abstract essential features without exposing implementation details. In an RMI setup, objects are remotely referenced through a registry, with stubs acting as local proxies to invoke methods on these objects using the skeleton or dispatcher. Data marshalling transforms platform-specific data into a universal format for remote method invocations. For security purposes, Java'e `java.security.policy` manages permissions and can be customized through policies stored in files. Distributed systems also have their object specifications accessed either from the local file system or over HTTP via a web server. \n",
      " Output: \n"
     ]
    }
   ],
   "source": [
    "\"\"\" The system prompt should be designed to use few-shot learning in order to generate the most accurate questions for the source material. \"\"\"\n",
    "\n",
    "\n",
    "SYSTEMPROMPT = f\"Instruct: Generate {QUESTIONNUMBER} questions, in a list. Each question should be written as a string, and should be separated by one new line character \\\\n each. Questions should not be numbered. \\nFor example, for 4 questions about famous authors would be generated as\\n \\\"Which author beginning with the letter M contributed the most to American literary fiction?\\\"\\\\n\\\"When was this author born?\\\"\\\\n\\\"Which famous comet was associated with this author?\\\"\\\\n\\\"Did this author have a pen-name?\\\"\\n \"\n",
    "\n",
    "if ALLQUESTIONTYPES[QUESTIONTYPE].examplePrompt != None:\n",
    "  SYSTEMPROMPT += ALLQUESTIONTYPES[QUESTIONTYPE].systemPrompt + ALLQUESTIONTYPES[QUESTIONTYPE].examplePrompt\n",
    "else:\n",
    "  SYSTEMPROMPT += ALLQUESTIONTYPES[QUESTIONTYPE].systemPrompt\n",
    "\n",
    "\"\"\"Adding notes specified by user.\"\"\"\n",
    "# if EXAMPLEQUESTIONS != \"\":\n",
    "#     SYSTEMPROMPT += f\"You must generate questions with a similar structure and form to the questions below: \\n {EXAMPLEQUESTIONS}\"\n",
    "SYSTEMPROMPT += f\"\\nPlease generate the questions from these notes: \\n {NOTES} \\n Output: \"\n",
    "print(SYSTEMPROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question [1] How does the TCP protocol contribute to reliable communication within distributed systems, particularly concerning interprocess communications?\n",
      "Question [2] In what ways do middleware tools like Java RMI enhance remote procedure calls in distributed computing environments, and how do they abstract away from implementation details for developers?\n",
      "Question [3] Can you elaborate on the role of data marshalling in facilitating cross-platform method invocations within a Remote Method Invocation (RMI) framework, including its impact on system performance?\n",
      "Question [4] How does Java's `java.security.policy` mechanism ensure security and manage permissions across distributed systems with diverse networked resources?\n",
      "Question [5] What are the advantages of accessing object specifications through both local file systems and HTTP web servers in a distributed computing environment, and how do these methods differ in their approach to resource sharing and accessibility?\n"
     ]
    }
   ],
   "source": [
    "generation = ollama.generate(model=MODELNAME, prompt=SYSTEMPROMPT)\n",
    "# print(generation[\"response\"])\n",
    "generated_questions = [question.replace(\n",
    "    \"\\\"\", \"\") for question in generation[\"response\"].split(\"\\\\n\")]\n",
    "# Filter out the blank spaces.\n",
    "generated_questions = [question.strip() for question in generated_questions if question != \"\"]\n",
    "\n",
    "# print(generated_questions)\n",
    "for q in range(len(generated_questions)):\n",
    "  print(f\"Question [{q+1}] {generated_questions[q]}\")\n",
    "\n",
    "\n",
    "if len(generated_questions) != QUESTIONNUMBER:\n",
    "  raise Exception(f\"Problem with generated question amount: expected {QUESTIONNUMBER}, got {len(generated_questions)}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUESTIONTYPE == 'mcq':\n",
    "  \"\"\" Generate choices for each question.\"\"\"\n",
    "  MCQOPTIONS = 4\n",
    "  QUESTIONDICT = {}\n",
    "  for question in generated_questions:\n",
    "    CHOICEPROMPT = f\"Generate a short correct answer, that is less than 10 words, to the question {question}. This answer should be summarised and should not include any notes or formatting. \\nFor example: for the question \\\"What is the capital of England?\\\" the output would be \\\"London\\\". \\nFor example: for the question \\\"How many seas are there in the world\\\" the output would be \\\"7\\\". \\nFor example: for the question \\\"What is an example of a JavaScript framework?\\\" the output would be \\\"React.js\\\"\"\n",
    "    # CHOICEPROMPT = f\"Please generate {MCQOPTIONS} different multiple choice answers for the question {question}. Each choice must be separated by a new line character \\\\n. \\nFor example, for the question: What is the capital of Germany? \\n The output should be: Cologne\\\\nFrankfurt\\\\nBerlin\\\\nHamburg. \\nFor the question: How many moons does Earth have? The output could be: 1\\\\n2\\\\n4\\\\n3. Each choice should not be in a numbered list.\"\n",
    "    # CHOICEPROMPT += f\"Whenever possible, take the answer from the notes \\n{NOTES}\\n, but the answer should not be vague. \"\n",
    "    correctChoiceGeneration = ollama.generate(\n",
    "        model=MODELNAME, prompt=CHOICEPROMPT)\n",
    "    \"\"\"Output Parser\"\"\"\n",
    "    choiceList = [choice.replace(\n",
    "        \"\\\"\", \"\") for choice in correctChoiceGeneration[\"response\"].split(\"\\\\n\") if choice != \"\"]\n",
    "    QUESTIONDICT[str(question)] = choiceList\n",
    "    print(question)\n",
    "    print(choiceList)\n",
    "    incorrectPrompt = f\"Generate {MCQOPTIONS - 1} options, that are similar but not the same as {choiceList[0]}. \\nFor example: for an option London, the output would be \\\"Edinburgh\\\\nGlasgow\\\\nAberdeen\\\\Leeds\\\". \\nFor example: for an option \\\"7\\\" the output would be \\\"4\\\\n6\\\\n2\\\\n9\\\". \\n\"\n",
    "    incorrectChoiceGeneration = ollama.generate(\n",
    "        model=MODELNAME, prompt=incorrectPrompt)\n",
    "    print(incorrectChoiceGeneration[\"response\"].split(\"\\\\n\"))\n",
    "    \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Add generated questions to a tex file.\"\"\"\n",
    "try:\n",
    "  with open(\"questions.tex\", \"w\") as questionTemplate:\n",
    "      if QUESTIONTYPE == \"short\":\n",
    "        # my_file.write(\"\\\\begin{parts}\\n\")\n",
    "        for question in generated_questions:\n",
    "          questionTemplate.write(\n",
    "              f\"\\\\question[{TOTALMARKS // QUESTIONNUMBER}] {question} \\n\")\n",
    "          questionTemplate.write(\"\\\\fillwithlines{0.75in}\")\n",
    "          # for i in range(5):\n",
    "          #   my_file.write(f\"\\\\newline\")\n",
    "          #   my_file.write(f\"{{\\\\rule{{\\\\linewidth}}{{0.5pt}}}} \\n\")\n",
    "          #   my_file.write(f\"\\\\newline\")\n",
    "          questionTemplate.write(f\"\\\\vspace{{0.5in}}\")\n",
    "          # [my_file.write(\"\\\\choice {choices}\") for choice in choices]\n",
    "          # my_file.write(f\"\\n\")\n",
    "        # my_file.write(\"\\\\end{parts}\")\n",
    "      elif QUESTIONTYPE == \"mcq\":   \n",
    "        # my_file.write(\"\\\\begin{parts}\\n\")\n",
    "        for question in generated_questions:  \n",
    "          questionTemplate.write(\n",
    "              f\"\\\\question[{TOTALMARKS // QUESTIONNUMBER}] {question} \\n\")\n",
    "          questionTemplate.write(\"\\\\begin{checkboxes} \\n\")\n",
    "          # [my_file.write(\"\\\\choice {choices}\") for choice in choices]\n",
    "          questionTemplate.write(\"\\\\end{checkboxes} \\n\")\n",
    "          # my_file.write(f\"\\n\")\n",
    "        # my_file.write(\"\\\\end{parts}\")\n",
    "      elif QUESTIONTYPE == \"long\":\n",
    "        # my_file.write(\"\\\\begin{parts}\\n\")\n",
    "        for question in generated_questions:\n",
    "          questionTemplate.write(\n",
    "              f\"\\\\question[{TOTALMARKS // QUESTIONNUMBER}] {question} \\n\")\n",
    "          # for i in range(10):\n",
    "          #   my_file.write(f\"\\\\newline\")\n",
    "          #   my_file.write(f\"{{\\\\rule{{\\\\linewidth}}{{0.5pt}}}} \\n\")\n",
    "          #   my_file.write(f\"\\\\newline\")\n",
    "          questionTemplate.write(\"\\\\fillwithlines{2in}\")\n",
    "          questionTemplate.write(f\"\\\\vspace{{0.5in}}\")\n",
    "          \n",
    "      else:\n",
    "        raise Exception(\"Behavior for questions not implemented.\")\n",
    "except OSError:\n",
    "   raise Exception(\"questions.tex does not exist and cannot be written to.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) (preloaded format=pdflatex)\n",
      " restricted \\write18 enabled.\n",
      "entering extended mode\n",
      "(./exam_1.tex\n",
      "LaTeX2e <2023-11-01> patch level 1\n",
      "L3 programming layer <2024-02-20>\n",
      "(/usr/local/texlive/2024basic/texmf-dist/tex/latex/exam/exam.cls\n",
      "Document Class: exam 2023/07/09 Version 2.704 by Philip Hirschhorn\n",
      "(/usr/local/texlive/2024basic/texmf-dist/tex/latex/base/ifthen.sty)\n",
      "(/usr/local/texlive/2024basic/texmf-dist/tex/latex/base/article.cls\n",
      "Document Class: article 2023/05/17 v1.4n Standard LaTeX document class\n",
      "(/usr/local/texlive/2024basic/texmf-dist/tex/latex/base/size10.clo)))\n",
      "(/usr/local/texlive/2024basic/texmf-dist/tex/latex/l3backend/l3backend-pdftex.d\n",
      "ef) (./exam_1.aux) (./questions.tex [1{/usr/local/texlive/2024basic/texmf-var/f\n",
      "onts/map/pdftex/updmap/pdftex.map}] [2]) [3]\n",
      "This exam contains 5 questions with 0 parts, 0 subparts, and 0 subsubparts.\n",
      "This exam has a total of 10 points.\n",
      "This exam has a total of 0 bonus points.\n",
      "(./exam_1.aux) )</usr/local/texlive/2024basic/texmf-dist/fonts/type1/public/ams\n",
      "fonts/cm/cmr10.pfb>\n",
      "Output written on exam_1.pdf (3 pages, 25164 bytes).\n",
      "Transcript written on exam_1.log.\n"
     ]
    }
   ],
   "source": [
    "def compileTeX(texFile:str):\n",
    "  \"\"\"Uses pdflatex to compile the file.\"\"\"\n",
    "  if texFile[-3:] == \"tex\":\n",
    "    subprocess.run([\"pdflatex\", \"-interaction\", \"nonstopmode\", texFile])\n",
    "  else:\n",
    "    raise Exception(\"This is not a tex file and cannot be compiled.\")\n",
    "\n",
    "compileTeX(\"exam_1.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 14:19:22.112 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/homebrew/Caskroom/miniconda/base/envs/lmpc/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Create Streamlit app.\"\"\"\n",
    "\n",
    "st.title(\"Magister\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
